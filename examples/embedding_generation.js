// =====================================================
// EXEMPLE: G√©n√©ration d'embedding avec OpenAI
// =====================================================

// 1. Installer: npm install openai
const { OpenAI } = require('openai');

// 2. Configurer avec votre cl√© API
const openai = new OpenAI({
  apiKey: 'sk-...', // Votre cl√© OpenAI
});

/**
 * G√©n√®re un embedding √† partir d'un texte
 * @param {string} text - Le texte √† transformer en vecteur
 * @returns {Promise<number[]>} - Vecteur de 768 nombres
 */
async function generateEmbedding(text) {
  try {
    // Appel √† l'API OpenAI
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small', // Mod√®le 768 dimensions
      input: text,
    });

    // R√©cup√©rer le vecteur
    const embedding = response.data[0].embedding;
    console.log(`‚úÖ Embedding g√©n√©r√©: ${embedding.length} dimensions`);
    return embedding;

  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration embedding:', error);
    throw error;
  }
}

// =====================================================
// UTILISATION CONCR√àTE
// =====================================================

async function searchWithRealEmbedding() {
  // 1. Question de l'utilisateur
  const userQuery = "Comment utiliser les transformers en Python?";

  // 2. G√©n√©rer l'embedding de cette question
  console.log('üîÑ G√©n√©ration embedding...');
  const queryVector = await generateEmbedding(userQuery);

  // 3. Utiliser CE vecteur pour la recherche
  console.log('üîç Recherche vectorielle...');
  const results = await pgvector_search({
    tableName: "documents",
    queryVector: queryVector,  // ‚Üê Vecteur bas√© sur le SENS du texte
    topK: 10
  });

  // 4. Afficher les r√©sultats
  console.log('üìä R√©sultats:');
  console.log(results);
}

// Ex√©cuter
searchWithRealEmbedding()
  .then(() => console.log('‚úÖ Termin√©'))
  .catch(err => console.error('‚ùå Erreur:', err));

// =====================================================
// VARIANTE: Sans API (mod√®le local)
// =====================================================

/**
 * Alternative: Mod√®le local (plus lent mais gratuit)
 * N√©cessite: npm install @xenova/transformers
 */
async function generateEmbeddingLocal(text) {
  const { pipeline } = await import('@xenova/transformers');

  // Charger le mod√®le (la premi√®re fois prend du temps)
  const extractor = await pipeline(
    'feature-extraction',
    'Xenova/all-mpnet-base-v2' // Mod√®le 768 dims
  );

  // Extraire les features
  const output = await extractor(text);
  const embedding = output.data; // Array de 768 nombres

  return Array.from(embedding);
}

// =====================================================
// WORKFLOW COMPLET
// =====================================================

/**
 * Fonction de recherche intelligente
 */
async function intelligentSearch(query, useHybrid = false) {
  // Mode TEST: Vecteur al√©atoire
  if (query.startsWith('TEST:')) {
    return {
      useRandomVector: true,
      dimensions: 768,
      topK: 10
    };
  }

  // Mode PROD: Vecteur r√©el
  const queryVector = await generateEmbedding(query);

  if (useHybrid) {
    // Recherche hybride: Full-text + Vecteur
    const textResults = await fullTextSearch(query);
    return {
      tableName: "documents",
      queryVector: queryVector,
      whereClause: `id IN (${textResults.map(r => r.id).join(',')})`,
      topK: 10
    };
  }

  // Recherche vectorielle simple
  return {
    tableName: "documents",
    queryVector: queryVector,
    topK: 10
  };
}
