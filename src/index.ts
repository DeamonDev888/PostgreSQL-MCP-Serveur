#!/usr/bin/env node

import { FastMCP } from 'fastmcp';
import { z } from 'zod';
import { Pool } from 'pg';
import config, { dbConfig } from './config.js';
import Logger from './utils/logger.js';
import { validateSQL } from './utils/sqlHelper.js';
import { DBOptimizer } from './utils/dbOptimizer.js';
import { PGVectorTools } from './tools/pgvector.js';

// IMPORTANT: Ne PAS utiliser console.log car cela corrupt le protocole MCP sur stdout !
// Rediriger console.log vers Logger.info
console.log = (...args: any[]) => {
  Logger.info('[STDOUT REDIRECT]', ...args);
};

// Initialisation du serveur MCP
const server = new FastMCP({
  name: 'postgresql-mcp-server',
  version: '1.0.0',
});

// Pool de connexions PostgreSQL
let pool: Pool | null = null;

// Ã‰tat global du serveur
const globalState = {
  isConnected: false,
  connectionInfo: null as any,
  lastError: null as string | null,
  connectionCount: 0,
};

// Fonction pour obtenir le pool de connexions
function getPool(): Pool {
  if (!pool) {
    pool = new Pool(config.database);

    // Gestionnaire d'Ã©vÃ©nements pour le pool
    pool.on('connect', () => {
      Logger.info('ğŸ”— Nouvelle connexion PostgreSQL Ã©tablie');
      globalState.connectionCount++;
      updateGlobalState(true);
    });

    pool.on('error', (err) => {
      Logger.error('âŒ Erreur du pool PostgreSQL:', err);
      updateGlobalState(false, err.message);
    });

    pool.on('remove', () => {
      globalState.connectionCount--;
      Logger.debug(`ğŸ“¤ Connexion retirÃ©e du pool. Total: ${globalState.connectionCount}`);
    });
  }
  return pool;
}

// Fonction pour mettre Ã  jour l'Ã©tat global
function updateGlobalState(connected: boolean, error?: string) {
  globalState.isConnected = connected;
  globalState.lastError = error || null;

  if (connected && pool) {
    globalState.connectionInfo = {
      host: config.database.connectionString?.split('@')[1]?.split('/')[0] || 'localhost',
      database: dbConfig.POSTGRES_DATABASE,
      activeConnections: globalState.connectionCount,
      maxConnections: config.database.max,
      sslEnabled: config.database.ssl !== false,
    };
  }
}

// ============================================================================
// ENREGISTREMENT DES MODULES D'OUTILS
// ============================================================================

// Enregistrer les outils pg_vector
const pgVectorTools = new PGVectorTools(getPool(), server);
pgVectorTools.registerTools();

// ============================================================================
// OUTILS MCP - EXPLORATION DE BASE DE DONNÃ‰ES
// ============================================================================

// 1. Statut de connexion PostgreSQL
server.addTool({
  name: 'postgres_status',
  description: 'VÃ©rifie le statut de connexion Ã  la base de donnÃ©es PostgreSQL',
  parameters: z.object({}),
  execute: async () => {
    try {
      const testPool = getPool();
      const client = await testPool.connect();

      // Test simple de connexion
      const result = await client.query('SELECT version() as version, current_database() as database, current_user as user');
      await client.release();

      const info = result.rows[0];

      return `âœ… ConnectÃ© Ã  PostgreSQL | Base: ${info.database} | Utilisateur: ${info.user} | Version: ${info.version.split(' ')[1]}`;
    } catch (error: any) {
      Logger.error('âŒ [postgres_status]', error.message);
      updateGlobalState(false, error.message);
      return `âŒ Erreur de connexion | ${error.message}`;
    }
  },
});

// 1.5. Diagnostic complet PostgreSQL
server.addTool({
  name: 'postgres_diagnose',
  description: "Diagnostic complet : vÃ©rifie Docker, PostgreSQL, base de donnÃ©es et fournit des solutions",
  parameters: z.object({
    checkDocker: z.boolean().optional().describe("VÃ©rifier si Docker est en cours d'exÃ©cution").default(true),
    checkPg: z.boolean().optional().describe("VÃ©rifier si PostgreSQL est accessible").default(true),
  }),
  execute: async (args) => {
    const diagnostics: string[] = [];
    let allGood = true;

    // 1. VÃ©rification de Docker
    if (args.checkDocker) {
      diagnostics.push('ğŸ” **Diagnostic Docker :**');
      try {
        const dockerCheck = await import('child_process').then(({ execSync }) => {
          try {
            execSync('docker --version', { stdio: 'ignore' });
            return 'âœ… Docker est installÃ©';
          } catch {
            return 'âŒ Docker n\'est pas installÃ© ou pas dans le PATH';
          }
        });
        diagnostics.push(dockerCheck);

        // VÃ©rifier si le conteneur PostgreSQL est en cours d'exÃ©cution
        try {
          const containerCheck = await import('child_process').then(({ execSync }) => {
            try {
              const output = execSync('docker ps --filter name=postgres --format "{{.Names}}"', { encoding: 'utf8' });
              if (output.trim()) {
                return `âœ… Conteneur PostgreSQL dÃ©tectÃ© : ${output.trim()}`;
              } else {
                return 'âš ï¸  Aucun conteneur PostgreSQL en cours d\'exÃ©cution';
              }
            } catch {
              return 'âš ï¸  Impossible de vÃ©rifier les conteneurs Docker';
            }
          });
          diagnostics.push(containerCheck);
        } catch {
          // Ignore errors for container check
        }
      } catch {
        diagnostics.push('âŒ Impossible de vÃ©rifier Docker');
      }
    }

    // 2. VÃ©rification de PostgreSQL
    if (args.checkPg) {
      diagnostics.push('\nğŸ” **Diagnostic PostgreSQL :**');
      diagnostics.push(`ğŸ“ Configuration :`);
      diagnostics.push(`   - HÃ´te : ${dbConfig.POSTGRES_HOST}:${dbConfig.POSTGRES_PORT}`);
      diagnostics.push(`   - Base : ${dbConfig.POSTGRES_DATABASE}`);
      diagnostics.push(`   - Utilisateur : ${dbConfig.POSTGRES_USER}`);

      // Test de connexion
      try {
        const testPool = getPool();
        const client = await testPool.connect();
        const result = await client.query('SELECT version() as version, current_database() as database');

        diagnostics.push('\nâœ… **Connexion PostgreSQL : RÃ‰USSIE**');
        diagnostics.push(`   - Version : ${result.rows[0].version.split(' ')[0]} ${result.rows[0].version.split(' ')[1]}`);
        diagnostics.push(`   - Base active : ${result.rows[0].database}`);
        diagnostics.push(`   - Statut : OpÃ©rationnel`);

        await client.release();
        allGood = allGood && true;
      } catch (error: any) {
        diagnostics.push('\nâŒ **Connexion PostgreSQL : Ã‰CHEC**');
        diagnostics.push(`   - Erreur : ${error.message}`);

        if (error.code === 'ECONNREFUSED') {
          diagnostics.push('\nğŸ”§ **Solutions possibles :**');
          diagnostics.push('   1. DÃ©marrer PostgreSQL :');
          diagnostics.push('      - Via Docker Desktop :');
          diagnostics.push('        â€¢ Lancez Docker Desktop manuellement');
          diagnostics.push('        â€¢ Attendez que l\'icÃ´ne indique "Running"');
          diagnostics.push('        â€¢ CrÃ©ez un conteneur PostgreSQL');
          diagnostics.push('      - Via service local : sudo systemctl start postgresql');
          diagnostics.push('   2. VÃ©rifier la configuration :');
          diagnostics.push(`      - HÃ´te actuel : ${dbConfig.POSTGRES_HOST}:${dbConfig.POSTGRES_PORT}`);
          diagnostics.push('      - Modifier .env si nÃ©cessaire');
        } else if (error.code === '28P01') {
          diagnostics.push('\nğŸ”§ **Solutions possibles :**');
          diagnostics.push('   - VÃ©rifier le nom d\'utilisateur et le mot de passe dans .env');
          diagnostics.push('   - CrÃ©er l\'utilisateur si nÃ©cessaire');
        } else if (error.code === '3D000') {
          diagnostics.push('\nğŸ”§ **Solutions possibles :**');
          diagnostics.push('   - CrÃ©er la base de donnÃ©es :');
          diagnostics.push(`      - CREATE DATABASE ${dbConfig.POSTGRES_DATABASE};`);
        }

        allGood = false;
      }
    }

    diagnostics.push('\n' + '='.repeat(50));
    if (allGood) {
      diagnostics.push('âœ… **Diagnostic global : TOUT EST OK**');
    } else {
      diagnostics.push('âš ï¸  **Diagnostic global : PROBLÃˆMES DÃ‰TECTÃ‰S**');
      diagnostics.push('\nğŸ’¡ **Actions recommandÃ©es :**');
      diagnostics.push('   1. DÃ©marrez Docker Desktop manuellement');
      diagnostics.push('   2. Ou configurez PostgreSQL local');
      diagnostics.push('   3. VÃ©rifiez votre configuration dans .env');
    }

    return diagnostics.join('\n');
  },
});

// 2. Lister les bases de donnÃ©es
server.addTool({
  name: 'list_databases',
  description: 'Liste toutes les bases de donnÃ©es accessibles',
  parameters: z.object({
    includeSize: z.boolean().optional().default(false).describe('Inclure la taille des bases de donnÃ©es'),
  }),
  execute: async (args) => {
    try {
      const pool = getPool();
      const client = await pool.connect();

      let query = `
        SELECT
          datname as database_name,
          datistemplate as is_template,
          datallowconn as allow_connection
        FROM pg_database
        WHERE datistemplate = false
        ORDER BY datname
      `;

      if (args.includeSize) {
        query = `
          SELECT
            d.datname as database_name,
            d.datistemplate as is_template,
            d.datallowconn as allow_connection,
            pg_size_pretty(pg_database_size(d.datname)) as size
          FROM pg_database d
          WHERE d.datistemplate = false
          ORDER BY d.datname
        `;
      }

      const result = await client.query(query);
      await client.release();

      const databases = result.rows.map((row: any, index: number) => {
        const status = row.allow_connection ? 'âœ…' : 'ğŸ”’';
        const size = args.includeSize ? ` (${row.size})` : '';
        return `${index + 1}. ${status} ${row.database_name}${size}`;
      }).join('\n');

      return `ğŸ“Š **Bases de donnÃ©es (${result.rows.length}):**\n${databases}`;
    } catch (error: any) {
      Logger.error('âŒ [list_databases]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 3. Lister les tables
server.addTool({
  name: 'list_tables',
  description: 'Liste toutes les tables d\'une base de donnÃ©es',
  parameters: z.object({
    schema: z.string().optional().default('public').describe('SchÃ©ma Ã  explorer (dÃ©faut: public)'),
    includeSize: z.boolean().optional().default(false).describe('Inclure la taille des tables'),
  }),
  execute: async (args) => {
    try {
      const pool = getPool();
      const client = await pool.connect();

      let query = `
        SELECT
          table_name,
          table_type
        FROM information_schema.tables
        WHERE table_schema = $1
        ORDER BY table_name
      `;

      if (args.includeSize) {
        query = `
          SELECT
            t.table_name,
            t.table_type,
            pg_size_pretty(pg_total_relation_size(c.oid)) as size
          FROM information_schema.tables t
          JOIN pg_class c ON c.relname = t.table_name
          WHERE t.table_schema = $1
          ORDER BY t.table_name
        `;
      }

      const result = await client.query(query, [args.schema]);
      await client.release();

      const tables = result.rows.map((row: any, index: number) => {
        const type = row.table_type === 'BASE TABLE' ? 'ğŸ“‹' : 'ğŸ”—';
        const size = args.includeSize ? ` (${row.size})` : '';
        return `${index + 1}. ${type} ${row.table_name}${size}`;
      }).join('\n');

      return `ğŸ“‹ **Tables du schÃ©ma '${args.schema}' (${result.rows.length}):**\n${tables}`;
    } catch (error: any) {
      Logger.error('âŒ [list_tables]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 4. DÃ©crire une table
server.addTool({
  name: 'describe_table',
  description: 'Affiche la structure dÃ©taillÃ©e d\'une table',
  parameters: z.object({
    table: z.string().describe('Nom de la table'),
    schema: z.string().optional().default('public').describe('SchÃ©ma de la table (dÃ©faut: public)'),
  }),
  execute: async (args) => {
    try {
      const pool = getPool();
      const client = await pool.connect();

      // Informations sur les colonnes
      const columnsQuery = `
        SELECT
          column_name,
          data_type,
          character_maximum_length,
          is_nullable,
          column_default,
          ordinal_position
        FROM information_schema.columns
        WHERE table_schema = $1 AND table_name = $2
        ORDER BY ordinal_position
      `;

      const columnsResult = await client.query(columnsQuery, [args.schema, args.table]);

      await client.release();

      if (columnsResult.rows.length === 0) {
        return `âŒ Table '${args.schema}.${args.table}' introuvable`;
      }

      // Formater les colonnes
      const columns = columnsResult.rows.map((col: any) => {
        const length = col.character_maximum_length ? `(${col.character_maximum_length})` : '';
        const nullable = col.is_nullable === 'YES' ? 'NULL' : 'NOT NULL';
        const def = col.column_default ? ` DEFAULT ${col.column_default}` : '';
        return `  â€¢ ${col.column_name}: ${col.data_type}${length} ${nullable}${def}`;
      }).join('\n');

      let result = `ğŸ“‹ **Table: ${args.schema}.${args.table}**\n\n`;
      result += `**Colonnes (${columnsResult.rows.length}):**\n${columns}\n`;

      return result;
    } catch (error: any) {
      Logger.error('âŒ [describe_table]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 5. ExÃ©cuter une requÃªte SQL
server.addTool({
  name: 'execute_query',
  description: 'ExÃ©cute une requÃªte SQL et retourne les rÃ©sultats',
  parameters: z.object({
    query: z.string().describe('RequÃªte SQL Ã  exÃ©cuter'),
    readonly: z.boolean().optional().default(true).describe('Mode lecture seule (recommandÃ©)'),
    limit: z.number().optional().default(100).describe('Nombre maximum de rÃ©sultats'),
  }),
  execute: async (args) => {
    try {
      // Validation de base de sÃ©curitÃ©
      const queryUpper = args.query.toUpperCase().trim();

      if (args.readonly) {
        const forbiddenKeywords = ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 'TRUNCATE'];
        const hasForbidden = forbiddenKeywords.some(keyword => queryUpper.includes(keyword));

        if (hasForbidden) {
          return `âŒ RequÃªte non autorisÃ©e en mode lecture seule. Mots-clÃ©s interdits: ${forbiddenKeywords.join(', ')}`;
        }
      }

      // Valider la syntaxe SQL
      const validation = validateSQL(args.query);
      if (!validation.valid) {
        return `âŒ Erreur de syntaxe SQL: ${validation.error}`;
      }

      const pool = getPool();
      const client = await pool.connect();

      try {
        // Ajouter une limite si pas prÃ©sente et si c'est un SELECT
        let finalQuery = args.query;
        if (!queryUpper.includes('LIMIT') && queryUpper.startsWith('SELECT')) {
          finalQuery = `SELECT * FROM (${args.query}) AS limited_query LIMIT ${args.limit}`;
        }

        const startTime = Date.now();
        const result = await client.query(finalQuery);
        const duration = Date.now() - startTime;

        // Formatter les rÃ©sultats
        let output = `âœ… **RequÃªte exÃ©cutÃ©e**\n`;
        output += `â±ï¸ DurÃ©e: ${duration}ms\n`;
        output += `ğŸ“Š RÃ©sultats: ${result.rows.length} ligne(s)\n\n`;

        if (result.rows.length > 0) {
          // EntÃªtes
          const headers = Object.keys(result.rows[0]);
          output += `| ${headers.join(' | ')} |\n`;
          output += `|${headers.map(() => '---').join('|')}|\n`;

          // DonnÃ©es (limitÃ©es Ã  50 lignes pour l'affichage)
          const displayRows = result.rows.slice(0, 50);
          displayRows.forEach((row: any) => {
            const values = headers.map((h: string) => {
              const val = row[h];
              if (val === null) return 'NULL';
              if (typeof val === 'object') return JSON.stringify(val);
              return String(val);
            });
            output += `| ${values.join(' | ')} |\n`;
          });

          if (result.rows.length > 50) {
            output += `\n... et ${result.rows.length - 50} autres lignes`;
          }
        }

        return output;
      } finally {
        await client.release();
      }
    } catch (error: any) {
      Logger.error('âŒ [execute_query]', error.message);
      return `âŒ Erreur SQL: ${error.message}`;
    }
  },
});

// 6. Valider une requÃªte SQL
server.addTool({
  name: 'validate_query',
  description: 'Valide la syntaxe d\'une requÃªte SQL sans l\'exÃ©cuter',
  parameters: z.object({
    query: z.string().describe('RequÃªte SQL Ã  valider'),
  }),
  execute: async (args) => {
    try {
      const validation = validateSQL(args.query);

      if (validation.valid) {
        return `âœ… **RequÃªte valide**\n\nğŸ’¡ Analyse:\n${validation.analysis}`;
      } else {
        return `âŒ **RequÃªte invalide**\n\nğŸ” Erreur: ${validation.error}\n\nğŸ’¡ Suggestion: ${validation.suggestion}`;
      }
    } catch (error: any) {
      Logger.error('âŒ [validate_query]', error.message);
      return `âŒ Erreur de validation: ${error.message}`;
    }
  },
});

// 7. Tester la connexion
server.addTool({
  name: 'test_connection',
  description: 'Teste la connexion Ã  la base de donnÃ©es',
  parameters: z.object({}),
  execute: async () => {
    try {
      const startTime = Date.now();
      const pool = getPool();
      const client = await pool.connect();

      const result = await client.query({
        text: 'SELECT 1 as test, version() as version',
        name: 'test-connection'
      });

      await client.release();
      const duration = Date.now() - startTime;

      return `âœ… **Connexion rÃ©ussie**\n\n` +
             `â±ï¸ Latence: ${duration}ms\n` +
             `ğŸ“Š Version: ${result.rows[0].version.split(' ')[1]}`;
    } catch (error: any) {
      Logger.error('âŒ [test_connection]', error.message);
      return `âŒ **Ã‰chec de connexion**\n\nğŸ” Erreur: ${error.message}`;
    }
  },
});

// 8. Obtenir les informations de connexion
server.addTool({
  name: 'get_connection_info',
  description: 'Affiche les informations dÃ©taillÃ©es de la connexion actuelle',
  parameters: z.object({}),
  execute: async () => {
    try {
      if (!globalState.isConnected) {
        return 'âŒ Non connectÃ© Ã  la base de donnÃ©es';
      }

      const info = globalState.connectionInfo;

      return `ğŸ”— **Informations de connexion**\n\n` +
             `ğŸ“Š HÃ´te: ${info.host}\n` +
             `ğŸ—„ï¸ Base: ${info.database}\n` +
             `ğŸ‘¤ Utilisateur: ${dbConfig.POSTGRES_USER}\n` +
             `ğŸ”Œ Connexions actives: ${info.activeConnections}/${info.maxConnections}\n` +
             `ğŸ”’ SSL: ${info.sslEnabled ? 'ActivÃ©' : 'DÃ©sactivÃ©'}\n` +
             `â±ï¸ Timeout inactivitÃ©: ${dbConfig.POSTGRES_IDLE_TIMEOUT}ms`;
    } catch (error: any) {
      Logger.error('âŒ [get_connection_info]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// ============================================================================
// OUTILS MCP - OPTIMISATION ET PERFORMANCE
// ============================================================================

// Fonction helper pour obtenir l'optimiseur
function getOptimizer(): DBOptimizer {
  const pool = getPool();
  return new DBOptimizer(pool);
}

// 9. Analyser les requÃªtes lentes
server.addTool({
  name: 'analyze_slow_queries',
  description: 'Analyse les requÃªtes les plus lentes de la base de donnÃ©es',
  parameters: z.object({
    limit: z.number().optional().default(10).describe('Nombre de requÃªtes Ã  analyser'),
  }),
  execute: async (args) => {
    try {
      const optimizer = getOptimizer();
      const slowQueries = await optimizer.getSlowQueries(args.limit);

      if (slowQueries.length === 0) {
        return 'âœ… Aucune requÃªte lente dÃ©tectÃ©e (pg_stat_statements doit Ãªtre activÃ©)';
      }

      let output = `ğŸŒ **${slowQueries.length} requÃªtes lentes dÃ©tectÃ©es**\n\n`;

      slowQueries.forEach((query, index) => {
        output += `**${index + 1}. Temps moyen: ${query.duration.toFixed(2)}ms**\n`;
        output += `ğŸ“Š Appels: ${query.calls} | Total: ${query.total_time.toFixed(2)}ms\n`;
        output += `\`\`\`sql\n${query.query}\n\`\`\`\n\n`;
      });

      return output;
    } catch (error: any) {
      Logger.error('âŒ [analyze_slow_queries]', error.message);

      // Message d'erreur amÃ©liorÃ© pour pg_stat_statements
      if (error.message.includes('pg_stat_statements') ||
          (error.message.includes('relation') && error.message.includes('does not exist'))) {
        return `âŒ **pg_stat_statements n'est pas activÃ©**

Cette fonctionnalitÃ© nÃ©cessite l'extension pg_stat_statements.

ğŸ“¦ **Activation de pg_stat_statements:**

1. **Ajouter Ã  postgresql.conf:**
\`\`\`
shared_preload_libraries = 'pg_stat_statements'
\`\`\`

2. **RedÃ©marrer PostgreSQL:**
\`\`\`bash
sudo systemctl restart postgresql
\`\`\`

3. **CrÃ©er l'extension dans la base:**
\`\`\`sql
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
\`\`\`

4. **VÃ©rifier:**
\`\`\`sql
SELECT * FROM pg_available_extensions WHERE name = 'pg_stat_statements';
\`\`\`

ğŸ’¡ pg_stat_statements est inclus par dÃ©faut dans PostgreSQL 10+`;
      }

      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 10. Analyser l'utilisation des index
server.addTool({
  name: 'analyze_index_usage',
  description: 'Analyse l\'utilisation des index et identifie les index non utilisÃ©s',
  parameters: z.object({}),
  execute: async () => {
    try {
      const optimizer = getOptimizer();
      const indexes = await optimizer.analyzeIndexUsage();

      const unused = indexes.filter(idx => idx.usage === 0);
      const lowUsage = indexes.filter(idx => idx.usage > 0 && idx.usage < 10);

      let output = `ğŸ“Š **Analyse des index (${indexes.length} trouvÃ©s)**\n\n`;

      if (unused.length > 0) {
        output += `ğŸ—‘ï¸ **Index non utilisÃ©s (${unused.length}):**\n`;
        unused.forEach(idx => {
          output += `â€¢ ${idx.indexname} sur ${idx.tablename} (${idx.size})\n`;
        });
        output += '\nğŸ’¡ **Action**: ConsidÃ©rez supprimer ces index pour amÃ©liorer les performances d\'Ã©criture\n\n';
      }

      if (lowUsage.length > 0) {
        output += `âš ï¸ **Index peu utilisÃ©s (${lowUsage.length}):**\n`;
        lowUsage.slice(0, 5).forEach(idx => {
          output += `â€¢ ${idx.indexname} sur ${idx.tablename}: ${idx.usage} utilisations (${idx.size})\n`;
        });
        output += '\n';
      }

      if (unused.length === 0 && lowUsage.length === 0) {
        output += 'âœ… Tous les index sont bien utilisÃ©s !\n\n';
      }

      const wellUsed = indexes.filter(idx => idx.usage >= 10);
      output += `âœ… **Index bien utilisÃ©s (${wellUsed.length}):**\n`;
      wellUsed.slice(0, 3).forEach(idx => {
        output += `â€¢ ${idx.indexname} sur ${idx.tablename}: ${idx.usage} utilisations\n`;
      });

      return output;
    } catch (error: any) {
      Logger.error('âŒ [analyze_index_usage]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 11. Analyser les statistiques des tables
server.addTool({
  name: 'analyze_table_stats',
  description: 'Affiche les statistiques dÃ©taillÃ©es des tables (scans, inserts, updates, etc.)',
  parameters: z.object({
    table: z.string().optional().describe('Table spÃ©cifique Ã  analyser (optionnel)'),
  }),
  execute: async (args) => {
    try {
      const optimizer = getOptimizer();
      const stats = await optimizer.getTableStatistics();

      let tables = stats;
      if (args.table) {
        tables = stats.filter(s => s.tablename === args.table);
        if (tables.length === 0) {
          return `âŒ Table '${args.table}' non trouvÃ©e`;
        }
      }

      let output = `ğŸ“Š **Statistiques des tables**\n\n`;

      tables.forEach(table => {
        const totalOps = table.n_tup_ins + table.n_tup_upd + table.n_tup_del;
        const deadTupleRatio = table.n_live_tup > 0 ? (table.n_dead_tup / (table.n_live_tup + table.n_dead_tup)) : 0;

        output += `## ğŸ“‹ ${table.tablename}\n`;
        output += `- **Lignes vivantes**: ${table.n_live_tup.toLocaleString()}\n`;
        output += `- **Lignes mortes**: ${table.n_dead_tup.toLocaleString()} (${(deadTupleRatio * 100).toFixed(1)}%)\n`;
        output += `- **Sequential scans**: ${table.seq_scan.toLocaleString()} (${table.seq_tup_read.toLocaleString()} lignes lues)\n`;
        output += `- **Index scans**: ${table.idx_scan.toLocaleString()} (${table.idx_tup_fetch.toLocaleString()} lignes via index)\n`;
        output += `- **OpÃ©rations**: ${totalOps.toLocaleString()} total\n`;
        output += `  â€¢ INSERT: ${table.n_tup_ins.toLocaleString()}\n`;
        output += `  â€¢ UPDATE: ${table.n_tup_upd.toLocaleString()}\n`;
        output += `  â€¢ DELETE: ${table.n_tup_del.toLocaleString()}\n`;

        if (deadTupleRatio > 0.2) {
          output += `âš ï¸ **Attention**: Ratio de tuples morts Ã©levÃ© (${(deadTupleRatio * 100).toFixed(1)}%) - VACUUM recommandÃ©\n`;
        }

        output += '\n';
      });

      return output;
    } catch (error: any) {
      Logger.error('âŒ [analyze_table_stats]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 12. SuggÃ©rer des index manquants
server.addTool({
  name: 'suggest_missing_indexes',
  description: 'SuggÃ¨re des index manquants basÃ©s sur les schÃ©mas d\'accÃ¨s aux donnÃ©es',
  parameters: z.object({}),
  execute: async () => {
    try {
      const optimizer = getOptimizer();
      const suggestions = await optimizer.suggestMissingIndexes();

      if (suggestions.length === 0) {
        return 'âœ… Aucune suggestion d\'index manquant dÃ©tectÃ©e';
      }

      let output = `ğŸ’¡ **${suggestions.length} suggestions d\'index manquants**\n\n`;

      suggestions.forEach((suggestion, index) => {
        const impactEmoji = suggestion.potential_impact === 'HIGH' ? 'ğŸ”´' :
                           suggestion.potential_impact === 'MEDIUM' ? 'ğŸŸ¡' : 'ğŸŸ¢';

        output += `${index + 1}. ${impactEmoji} **Table: ${suggestion.table}** (${suggestion.potential_impact} impact)\n`;
        output += `   Colonnes: ${suggestion.columns}\n`;
        output += `   Gain estimÃ©: ${suggestion.estimated_gain}\n`;
        output += `   \`\`\`sql\n${suggestion.suggested_index}\n   \`\`\`\n\n`;
      });

      return output;
    } catch (error: any) {
      Logger.error('âŒ [suggest_missing_indexes]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 13. Analyser les performances du cache
server.addTool({
  name: 'analyze_cache_performance',
  description: 'Analyse les performances du cache PostgreSQL (buffer cache hit ratio)',
  parameters: z.object({}),
  execute: async () => {
    try {
      const optimizer = getOptimizer();
      const cacheStats = await optimizer.getCacheHitRatios();

      const heapRatio = (cacheStats.heap_ratio || 0) * 100;
      const idxRatio = (cacheStats.idx_ratio || 0) * 100;

      let output = `ğŸ¯ **Performance du Cache PostgreSQL**\n\n`;

      output += `**Cache Tables**: ${heapRatio.toFixed(2)}%\n`;
      output += `**Cache Index**: ${idxRatio.toFixed(2)}%\n\n`;

      // Statistiques brutes
      output += `## ğŸ“Š Statistiques brutes\n`;
      output += `â€¢ **Heap blocks lus (disque)**: ${parseInt(cacheStats.heap_read || 0).toLocaleString()}\n`;
      output += `â€¢ **Heap blocks en cache****: ${parseInt(cacheStats.heap_hit || 0).toLocaleString()}\n`;
      output += `â€¢ **Index blocks lus (disque)**: ${parseInt(cacheStats.idx_read || 0).toLocaleString()}\n`;
      output += `â€¢ **Index blocks en cache**: ${parseInt(cacheStats.idx_hit || 0).toLocaleString()}\n\n`;

      // Analyse et recommandations
      output += `## ğŸ“Š Analyse\n`;

      if (heapRatio >= 99) {
        output += `âœ… **Cache tables excellent** (${heapRatio.toFixed(2)}%)\n`;
      } else if (heapRatio >= 95) {
        output += `âœ… **Cache tables bon** (${heapRatio.toFixed(2)}%)\n`;
      } else if (heapRatio >= 90) {
        output += `âš ï¸ **Cache tables moyen** (${heapRatio.toFixed(2)}%)\n`;
      } else if (heapRatio >= 80) {
        output += `ğŸ”´ **Cache tables faible** (${heapRatio.toFixed(2)}%)\n`;
      } else {
        output += `ğŸš¨ **Cache tables critique** (${heapRatio.toFixed(2)}%)\n`;
      }

      if (idxRatio >= 99) {
        output += `âœ… **Cache index excellent** (${idxRatio.toFixed(2)}%)\n`;
      } else if (idxRatio >= 95) {
        output += `âœ… **Cache index bon** (${idxRatio.toFixed(2)}%)\n`;
      } else if (idxRatio >= 90) {
        output += `âš ï¸ **Cache index moyen** (${idxRatio.toFixed(2)}%)\n`;
      } else if (idxRatio >= 80) {
        output += `ğŸ”´ **Cache index faible** (${idxRatio.toFixed(2)}%)\n`;
      } else {
        output += `ğŸš¨ **Cache index critique** (${idxRatio.toFixed(2)}%)\n`;
      }

      output += `\n## ğŸ’¡ Recommandations\n`;

      if (heapRatio < 95 || idxRatio < 95) {
        const isCritical = heapRatio < 85 || idxRatio < 85;

        if (isCritical) {
          output += `ğŸš¨ **Action requise immÃ©diatement**\n\n`;

          // Recommandations spÃ©cifiques avec valeurs
          output += `### 1. Configuration PostgreSQL (postgresql.conf)\n\n`;
          output += `**shared_buffers** (mÃ©moire partagÃ©e):\n`;
          output += `â€¢ Serveur dÃ©diÃ©: 25% de la RAM\n`;
          output += `â€¢ Serveur partagÃ©: 10-15% de la RAM\n`;
          output += `â€¢ Exemple (8GB RAM): \`shared_buffers = 2GB\`\n`;
          output += `â€¢ Exemple (16GB RAM): \`shared_buffers = 4GB\`\n\n`;

          output += `**effective_cache_size** (estimation OS cache):\n`;
          output += `â€¢ Serveur dÃ©diÃ©: 75% de la RAM\n`;
          output += `â€¢ Serveur partagÃ©: 25-50% de la RAM\n`;
          output += `â€¢ Exemple (8GB RAM): \`effective_cache_size = 6GB\`\n\n`;

          output += `**random_page_cost** (coÃ»t accÃ¨s alÃ©atoire):\n`;
          output += `â€¢ Avec SSD: \`random_page_cost = 1.1\` (dÃ©faut: 4.0)\n`;
          output += `â€¢ Avec HDD: \`random_page_cost = 2.0-4.0\`\n\n`;

          output += `**work_mem** (mÃ©moire par opÃ©ration):\n`;
          output += `â€¢ Calculez: \`work_mem = (RAM - shared_buffers) / (max_connections * 3)\`\n`;
          output += `â€¢ Exemple: \`work_mem = 16MB\` ou \`work_mem = 32MB\`\n\n`;

          output += `### 2. Diagnostic approfondi\n\n`;
          output += `ExÃ©cutez ces requÃªtes pour identifier les tables problÃ©matiques:\n\n`;
          output += `\`\`\`sql
-- Tables avec le plus de lectures disque
SELECT
  schemaname,
  relname as table_name,
  heap_blks_read,
  heap_blks_hit,
  CASE
    WHEN heap_blks_read + heap_blks_hit > 0
    THEN (heap_blks_hit::float / (heap_blks_read + heap_blks_hit) * 100)
    ELSE 0
  END as cache_hit_ratio
FROM pg_statio_user_tables
WHERE heap_blks_read > 1000
ORDER BY heap_blks_read DESC
LIMIT 10;
\`\`\`\n\n`;

          output += `\`\`\`sql
-- Index avec le plus de lectures disque
SELECT
  schemaname,
  relname as table_name,
  indexrelname as index_name,
  idx_blks_read,
  idx_blks_hit,
  CASE
    WHEN idx_blks_read + idx_blks_hit > 0
    THEN (idx_blks_hit::float / (idx_blks_read + idx_blks_hit) * 100)
    ELSE 0
  END as cache_hit_ratio
FROM pg_statio_user_indexes
WHERE idx_blks_read > 100
ORDER BY idx_blks_read DESC
LIMIT 10;
\`\`\`\n\n`;

          output += `### 3. Actions immÃ©diates\n\n`;
          output += `â€¢ **RedÃ©marrez PostgreSQL** aprÃ¨s avoir modifiÃ© postgresql.conf\n`;
          output += `â€¢ ExÃ©cutez \`ANALYZE\` sur les tables frÃ©quemment accÃ©dÃ©es\n`;
          output += `â€¢ VÃ©rifiez les tables avec beaucoup de sequential scans (outil: analyze_table_stats)\n`;
          output += `â€¢ Envisagez d'ajouter des index sur les colonnes frÃ©quemment filtrÃ©es\n`;

          // Recommandations pour RAM spÃ©cifique
          output += `\n### 4. Configuration recommandÃ©e par taille de RAM\n\n`;
          output += `| RAM | shared_buffers | effective_cache_size | work_mem |\n`;
          output += `|-----|----------------|---------------------|----------|\n`;
          output += `| 4GB | 512MB | 2GB | 4MB |\n`;
          output += `| 8GB | 2GB | 6GB | 16MB |\n`;
          output += `| 16GB | 4GB | 12GB | 32MB |\n`;
          output += `| 32GB | 8GB | 24GB | 64MB |\n`;
          output += `| 64GB | 16GB | 48GB | 128MB |\n`;

        } else {
          // Cas modÃ©rÃ© (90-95%)
          output += `â€¢ **Augmentez shared_buffers** de 10-20%\n`;
          output += `â€¢ **VÃ©rifiez effective_cache_size** dans postgresql.conf\n`;
          output += `â€¢ **Ajustez random_page_cost** si vous utilisez un SSD (1.1 au lieu de 4.0)\n`;
          output += `â€¢ **ExÃ©cutez ANALYZE** rÃ©guliÃ¨rement sur les tables actives\n`;
        }

        output += `\n### ğŸ“ˆ VÃ©rification des paramÃ¨tres actuels\n\n`;
        output += `ExÃ©cutez cette requÃªte pour voir votre configuration actuelle:\n\n`;
        output += `\`\`\`sql
SELECT name, setting, unit, context
FROM pg_settings
WHERE name IN ('shared_buffers', 'effective_cache_size', 'work_mem', 'random_page_cost', 'maintenance_work_mem')
ORDER BY name;
\`\`\`\n`;

      } else {
        output += `âœ… Les performances du cache sont optimales !\n`;
        output += `Aucune action nÃ©cessaire.\n`;
      }

      return output;
    } catch (error: any) {
      Logger.error('âŒ [analyze_cache_performance]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 14. Tables nÃ©cessitant un VACUUM
server.addTool({
  name: 'analyze_vacuum_needs',
  description: 'Identifie les tables qui nÃ©cessitent un VACUUM ou ANALYZE',
  parameters: z.object({
    threshold: z.number().optional().default(0.1).describe('Seuil de tuples morts (dÃ©faut: 10%)'),
  }),
  execute: async (args) => {
    try {
      const optimizer = getOptimizer();
      const tables = await optimizer.getTablesNeedingVacuum();

      const filteredTables = tables.filter(table =>
        parseFloat(table.dead_tuple_percent) >= args.threshold
      );

      if (filteredTables.length === 0) {
        return `âœ… Aucune table ne nÃ©cessite de VACUUM (seuil: ${(args.threshold * 100).toFixed(0)}%)`;
      }

      let output = `ğŸ§¹ **${filteredTables.length} table(s) nÃ©cessitent un VACUUM**\n\n`;

      filteredTables.forEach((table, index) => {
        const needsVacuum = parseFloat(table.dead_tuple_percent) > 0.2;
        const emoji = needsVacuum ? 'ğŸ”´' : 'ğŸŸ¡';

        output += `${index + 1}. ${emoji} **${table.tablename}**\n`;
        output += `   Tuples morts: ${table.dead_tuple_percent}%\n`;
        output += `   Taille: ${table.table_size}\n`;
        output += `   Lignes vivantes: ${parseInt(table.n_live_tup).toLocaleString()}\n`;
        output += `   Dernier VACUUM: ${table.last_vacuum || 'Jamais'}\n`;
        output += `   Dernier AUTOVACUUM: ${table.last_autovacuum || 'Jamais'}\n`;

        if (needsVacuum) {
          output += `   \`\`\`sql\nVACUUM ANALYZE ${table.tablename};\n   \`\`\`\n`;
        }

        output += '\n';
      });

      return output;
    } catch (error: any) {
      Logger.error('âŒ [analyze_vacuum_needs]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 15. Analyser les locks actifs
server.addTool({
  name: 'analyze_active_locks',
  description: 'Affiche les locks actifs et les requÃªtes en attente',
  parameters: z.object({}),
  execute: async () => {
    try {
      const optimizer = getOptimizer();
      const locks = await optimizer.getActiveLocks();
      const queries = await optimizer.getRunningQueries();

      let output = `âš¡ **Analyse de l\'activitÃ© en cours**\n\n`;

      if (queries.length === 0 && locks.length === 0) {
        return 'âœ… Aucune requÃªte ou lock actif dÃ©tectÃ©';
      }

      if (queries.length > 0) {
        output += `## ğŸ”„ RequÃªtes en cours (${queries.length})\n`;
        queries.slice(0, 5).forEach((query, index) => {
          const duration = query.duration ? ` (${query.duration})` : '';
          output += `${index + 1}. **Utilisateur**: ${query.username}\n`;
          output += `   Ã‰tat: ${query.state}\n`;
          output += `   Application: ${query.application_name || 'N/A'}\n`;
          output += `   DurÃ©e${duration}\n`;
          if (query.wait_event_type && query.wait_event_type !== 'Activity') {
            output += `   â³ En attente: ${query.wait_event_type} - ${query.wait_event}\n`;
          }
          output += '\n';
        });
      }

      if (locks.length > 0) {
        output += `## ğŸ”’ Locks actifs (${locks.length})\n`;
        locks.slice(0, 5).forEach((lock, index) => {
          output += `${index + 1}. **Table**: ${lock.table_name}\n`;
          output += `   Mode: ${lock.mode}\n`;
          output += `   AccordÃ©: ${lock.granted ? 'âœ…' : 'âŒ'}\n`;
          output += `   Utilisateur: ${lock.username}\n`;
          if (lock.duration) {
            output += `   DurÃ©e: ${lock.duration}\n`;
          }
          output += '\n';
        });
      }

      return output;
    } catch (error: any) {
      Logger.error('âŒ [analyze_active_locks]', error.message);
      return `âŒ Erreur: ${error.message}`;
    }
  },
});

// 16. GÃ©nÃ©rer un rapport d'optimisation complet
server.addTool({
  name: 'generate_optimization_report',
  description: 'GÃ©nÃ¨re un rapport complet d\'optimisation de la base de donnÃ©es',
  parameters: z.object({}),
  execute: async () => {
    try {
      const optimizer = getOptimizer();
      const report = await optimizer.generateOptimizationReport();

      return report;
    } catch (error: any) {
      Logger.error('âŒ [generate_optimization_report]', error.message);
      return `âŒ Erreur lors de la gÃ©nÃ©ration du rapport: ${error.message}`;
    }
  },
});

// ============================================================================
// NETTOYAGE ET DÃ‰MARRAGE
// ============================================================================

async function cleanup() {
  Logger.info('ğŸ§¹ Nettoyage du serveur PostgreSQL MCP...');
  try {
    if (pool) {
      await pool.end();
      pool = null;
    }
    Logger.info('âœ… Nettoyage terminÃ©');
  } catch (error) {
    Logger.error('âŒ Erreur lors du nettoyage:', error);
  }
}

process.on('SIGINT', async () => {
  await cleanup();
  process.exit(0);
});

process.on('SIGTERM', async () => {
  await cleanup();
  process.exit(0);
});

// Gestion des erreurs non capturÃ©es
process.on('uncaughtException', error => {
  Logger.error('âŒ Erreur non capturÃ©e:', error);
  process.exit(1);
});

process.on('unhandledRejection', (reason, promise) => {
  Logger.error('âŒ Promesse rejetÃ©e non gÃ©rÃ©e:', reason);
  process.exit(1);
});

// DÃ©marrage du serveur
async function main() {
  Logger.info('ğŸš€ DÃ©marrage PostgreSQL MCP Server v1.0.0...\n');

  try {
    // Tester la connexion au dÃ©marrage
    const testPool = getPool();
    const client = await testPool.connect();
    await client.query('SELECT 1');
    await client.release();

    updateGlobalState(true);
    Logger.info('âœ… Connexion PostgreSQL Ã©tablie\n');

    // DÃ©marrer le serveur MCP
    await server.start();
    Logger.info('âœ… Serveur MCP dÃ©marrÃ©\n');

    Logger.info('ğŸ“Š Serveur PostgreSQL MCP prÃªt:');
    Logger.info(`   â€¢ Base: ${dbConfig.POSTGRES_DATABASE}`);
    Logger.info(`   â€¢ HÃ´te: ${dbConfig.POSTGRES_HOST}:${dbConfig.POSTGRES_PORT}`);
    Logger.info(`   â€¢ SSL: ${config.database.ssl !== false ? 'ActivÃ©' : 'DÃ©sactivÃ©'}`);
    Logger.info(`   â€¢ Outils: 26 (exploration, requÃªtes, optimisation, performance, pg_vector)`);
  } catch (error) {
    Logger.error('âŒ Erreur fatal:', error);
    await cleanup();
    process.exit(1);
  }
}

main();